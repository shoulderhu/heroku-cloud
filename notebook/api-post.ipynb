{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = SparkConf().setMaster(\"local\")\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.108:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sc.textFile(\"hdfs://192.168.1.100:9000/csv/aqi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PM25,PM10,so2,o3,no2,co,測站,空品區,datetime'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = text.first()\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.0,53.0,1.9,26.0,11.0,0.28,安南,雲嘉南,2019-01-01 00:00:00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = text.filter(lambda x: x != first)\n",
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['21.0',\n",
       "  '53.0',\n",
       "  '1.9',\n",
       "  '26.0',\n",
       "  '11.0',\n",
       "  '0.28',\n",
       "  '安南',\n",
       "  '雲嘉南',\n",
       "  '2019-01-01 00:00:00'],\n",
       " ['15.0',\n",
       "  '51.0',\n",
       "  '2.3',\n",
       "  '28.0',\n",
       "  '11.0',\n",
       "  '0.29',\n",
       "  '安南',\n",
       "  '雲嘉南',\n",
       "  '2019-01-01 01:00:00']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.map(lambda x: x.split(\",\"))\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-01-01 00:00:00',\n",
       " '2019-01-01 01:00:00',\n",
       " '2019-01-01 02:00:00',\n",
       " '2019-01-01 03:00:00',\n",
       " '2019-01-01 04:00:00',\n",
       " '2019-01-01 05:00:00',\n",
       " '2019-01-01 06:00:00',\n",
       " '2019-01-01 07:00:00',\n",
       " '2019-01-01 08:00:00',\n",
       " '2019-01-01 09:00:00',\n",
       " '2019-01-01 10:00:00',\n",
       " '2019-01-01 11:00:00',\n",
       " '2019-01-01 12:00:00',\n",
       " '2019-01-01 13:00:00',\n",
       " '2019-01-01 14:00:00',\n",
       " '2019-01-01 15:00:00',\n",
       " '2019-01-01 16:00:00',\n",
       " '2019-01-01 17:00:00',\n",
       " '2019-01-01 18:00:00',\n",
       " '2019-01-01 19:00:00',\n",
       " '2019-01-01 20:00:00',\n",
       " '2019-01-01 21:00:00',\n",
       " '2019-01-01 22:00:00',\n",
       " '2019-01-01 23:00:00']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: x[8]).filter(lambda x: \"2019-01-01\" in x).distinct().sortBy(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中部', '高屏', '宜蘭', '花東', '竹苗', '雲嘉南', '北部', '外島']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone = data.map(lambda x: x[7]).distinct().collect()\n",
    "zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['金門', '馬公', '馬祖']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone = data.filter(lambda x: x[7] == \"外島\").map(lambda x: x[6]).distinct().collect()\n",
    "zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29.0',\n",
       " '29.0',\n",
       " '27.0',\n",
       " '26.0',\n",
       " '24.0',\n",
       " '27.0',\n",
       " '26.0',\n",
       " '28.0',\n",
       " '16.0',\n",
       " '18.0',\n",
       " '42.0',\n",
       " '44.0',\n",
       " '52.0',\n",
       " '59.0',\n",
       " '63.0',\n",
       " '60.0',\n",
       " '65.0',\n",
       " '62.0',\n",
       " '57.0',\n",
       " '55.0',\n",
       " '58.0',\n",
       " '62.0',\n",
       " '60.0',\n",
       " '56.0']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(lambda x: x[6] == \"金門\" and \"2019-01-01\" in x[8]).sortBy(lambda x: x[8]).map(lambda x: x[3]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['70.0',\n",
       "  '99.0',\n",
       "  '2.8',\n",
       "  '29.0',\n",
       "  '14.0',\n",
       "  '0.94',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 00:00:00'],\n",
       " ['73.0',\n",
       "  '103.0',\n",
       "  '4.4',\n",
       "  '29.0',\n",
       "  '15.0',\n",
       "  '0.98',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 01:00:00'],\n",
       " ['72.0',\n",
       "  '102.0',\n",
       "  '4.5',\n",
       "  '27.0',\n",
       "  '13.0',\n",
       "  '0.85',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 02:00:00'],\n",
       " ['71.0',\n",
       "  '102.0',\n",
       "  '4.9',\n",
       "  '26.0',\n",
       "  '13.0',\n",
       "  '0.81',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 03:00:00'],\n",
       " ['72.0',\n",
       "  '101.0',\n",
       "  '5.4',\n",
       "  '24.0',\n",
       "  '13.0',\n",
       "  '0.77',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 04:00:00'],\n",
       " ['25.0',\n",
       "  '57.0',\n",
       "  '5.2',\n",
       "  '27.0',\n",
       "  '14.0',\n",
       "  '0.35',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 05:00:00'],\n",
       " ['31.0',\n",
       "  '62.0',\n",
       "  '5.3',\n",
       "  '26.0',\n",
       "  '14.0',\n",
       "  '0.3',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 06:00:00'],\n",
       " ['35.0',\n",
       "  '56.0',\n",
       "  '4.4',\n",
       "  '28.0',\n",
       "  '13.0',\n",
       "  '0.27',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 07:00:00'],\n",
       " ['71.0',\n",
       "  '97.0',\n",
       "  '5.4',\n",
       "  '16.0',\n",
       "  '17.0',\n",
       "  '0.83',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 08:00:00'],\n",
       " ['63.0',\n",
       "  '85.0',\n",
       "  '5.1',\n",
       "  '18.0',\n",
       "  '16.0',\n",
       "  '0.8',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 09:00:00'],\n",
       " ['22.0',\n",
       "  '40.0',\n",
       "  '4.2',\n",
       "  '42.0',\n",
       "  '8.2',\n",
       "  '0.25',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 10:00:00'],\n",
       " ['21.0',\n",
       "  '49.0',\n",
       "  '3.7',\n",
       "  '44.0',\n",
       "  '8.6',\n",
       "  '0.27',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 11:00:00'],\n",
       " ['22.0',\n",
       "  '44.0',\n",
       "  '3.1',\n",
       "  '52.0',\n",
       "  '8.1',\n",
       "  '0.27',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 12:00:00'],\n",
       " ['24.0',\n",
       "  '43.0',\n",
       "  '2.9',\n",
       "  '59.0',\n",
       "  '7.2',\n",
       "  '0.25',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 13:00:00'],\n",
       " ['23.0',\n",
       "  '45.0',\n",
       "  '2.9',\n",
       "  '63.0',\n",
       "  '6.4',\n",
       "  '0.24',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 14:00:00'],\n",
       " ['19.0',\n",
       "  '38.0',\n",
       "  '2.8',\n",
       "  '60.0',\n",
       "  '6.0',\n",
       "  '0.23',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 15:00:00'],\n",
       " ['62.0',\n",
       "  '88.0',\n",
       "  '2.9',\n",
       "  '65.0',\n",
       "  '12.0',\n",
       "  '0.75',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 16:00:00'],\n",
       " ['59.0',\n",
       "  '81.0',\n",
       "  '2.5',\n",
       "  '62.0',\n",
       "  '12.0',\n",
       "  '0.67',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 17:00:00'],\n",
       " ['57.0',\n",
       "  '86.0',\n",
       "  '2.8',\n",
       "  '57.0',\n",
       "  '14.0',\n",
       "  '0.65',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 18:00:00'],\n",
       " ['55.0',\n",
       "  '90.0',\n",
       "  '3.2',\n",
       "  '55.0',\n",
       "  '15.0',\n",
       "  '0.6',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 19:00:00'],\n",
       " ['55.0',\n",
       "  '82.0',\n",
       "  '3.6',\n",
       "  '58.0',\n",
       "  '13.0',\n",
       "  '0.53',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 20:00:00'],\n",
       " ['55.0',\n",
       "  '86.0',\n",
       "  '2.9',\n",
       "  '62.0',\n",
       "  '11.0',\n",
       "  '0.5',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 21:00:00'],\n",
       " ['54.0',\n",
       "  '91.0',\n",
       "  '2.5',\n",
       "  '60.0',\n",
       "  '11.0',\n",
       "  '0.51',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 22:00:00'],\n",
       " ['57.0',\n",
       "  '91.0',\n",
       "  '3.2',\n",
       "  '56.0',\n",
       "  '11.0',\n",
       "  '0.54',\n",
       "  '金門',\n",
       "  '外島',\n",
       "  '2019-01-01 23:00:00']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(lambda x: x[6] == \"金門\" and \"2019-01-01\" in x[8]).sortBy(lambda x: x[8]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = data.filter(lambda x: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14.0',\n",
       "  '48.0',\n",
       "  '2.1',\n",
       "  '15.0',\n",
       "  '17.0',\n",
       "  '0.47',\n",
       "  '左營',\n",
       "  '高屏',\n",
       "  '2019-01-01 00:00:00'],\n",
       " ['22.0',\n",
       "  '47.0',\n",
       "  '2.5',\n",
       "  '14.0',\n",
       "  '16.0',\n",
       "  '0.36',\n",
       "  '左營',\n",
       "  '高屏',\n",
       "  '2019-01-01 01:00:00']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = data.filter(lambda x: x[6] == \"左營\")\n",
    "d.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = d.map(lambda x: x[3:4] + x[8:9])\n",
    "a = e.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = sc.textFile(\"hdfs://name:9000/csv/student.csv\")\n",
    "first2 = text2.first()\n",
    "data2 = text2.filter(lambda x: x != first2)\n",
    "data2 = data2.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aqi_filter():\n",
    "    d = data2.filter(lambda x: x[6] == \"左營\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class Livy:\n",
    "    def __init__(self, file):\n",
    "        text = sc.textFile(\"hdfs://192.168.1.100:9000/csv/aqi.csv\")\n",
    "        first = text.first()\n",
    "        self.data = text.filter(lambda x: x != first)\n",
    "        self.data = self.data.map(lambda x: x.split(\",\"))\n",
    "        \n",
    "    def filtering(self, tab, zone, time):\n",
    "        ret = []\n",
    "        t = self.data.filter(lambda x: time in x[8]).distinct().collect()\n",
    "        \n",
    "        d = self.data.filter(lambda x: x[6] == \"左營\")\n",
    "        d = d.map(lambda x: x[3:4] + x[8:9])\n",
    "        #n = np.array(d.collect())\n",
    "        return d.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Livy(\"aqi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l.filtering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-13d657d4e01e>:2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-94def54eae26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-94def54eae26>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSpark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hdfs://192.168.1.100:9000/csv/aqi.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/heroku-cloud-www/venv/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/GitHub/heroku-cloud-www/venv/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 332\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-13d657d4e01e>:2 "
     ]
    }
   ],
   "source": [
    "class Spark:\n",
    "    def __init__(self):\n",
    "        sc = SparkContext()\n",
    "        text = sc.textFile(\"hdfs://192.168.1.100:9000/csv/aqi.csv\")\n",
    "        first = text.first()\n",
    "        self.data = text.filter(lambda x: x != first)\n",
    "        self.data = self.data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "    def filtering(self, zone, time):\n",
    "        d = self.data.filter(lambda x: x[6] == \"左營\")\n",
    "        d = d.filter(lambda x: time in x[8])\n",
    "        d = d.map(lambda x: x[3:4] + x[8:9])\n",
    "        return d.collect()\n",
    "\n",
    "\n",
    "s = Spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a789206a7512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m words = sc.parallelize (\n\u001b[0m\u001b[1;32m      2\u001b[0m    [\"scala\", \n\u001b[1;32m      3\u001b[0m    \u001b[0;34m\"java\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;34m\"hadoop\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "words = sc.parallelize (\n",
    "   [\"scala\", \n",
    "   \"java\", \n",
    "   \"hadoop\", \n",
    "   \"spark\", \n",
    "   \"akka\",\n",
    "   \"spark vs hadoop\", \n",
    "   \"pyspark\",\n",
    "   \"pyspark and spark\"]\n",
    ")\n",
    "def f(x): \n",
    "    print(x)\n",
    "fore = words.foreach(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"2019-01-01 00:00:00\"\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a in \"2019-01-01 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.234, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.234, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.234, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
